{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b96da76c",
      "metadata": {
        "id": "b96da76c"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "14738749",
      "metadata": {
        "id": "14738749"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "file_path = 'SMSSpamCollection'\n",
        "df = pd.read_csv(file_path, sep='\\t', header=None, names=['label', 'message'])\n",
        "\n",
        "# Convert labels to binary values: spam as 1 and ham as 0\n",
        "df['label'] = df['label'].map({'spam': 1, 'ham': 0})\n",
        "\n",
        "# Split the dataset into training, validation, and test sets\n",
        "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "train, val = train_test_split(train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f4412a9b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4412a9b",
        "outputId": "a2c9a92d-04c3-47f3-8678-22908ab29a65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   label                                            message\n",
            "0      0  Go until jurong point, crazy.. Available only ...\n",
            "1      0                      Ok lar... Joking wif u oni...\n",
            "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3      0  U dun say so early hor... U c already then say...\n",
            "4      0  Nah I don't think he goes to usf, he lives aro...\n",
            "Dataset Shape: (5572, 2)\n",
            "             label\n",
            "count  5572.000000\n",
            "mean      0.134063\n",
            "std       0.340751\n",
            "min       0.000000\n",
            "25%       0.000000\n",
            "50%       0.000000\n",
            "75%       0.000000\n",
            "max       1.000000\n",
            "\n",
            "Missing Values: label      0\n",
            "message    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Display the first few rows of the dataset\n",
        "print(df.head())\n",
        "\n",
        "# Display the shape of the dataset\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "\n",
        "# Basic statistics and check for missing values\n",
        "print(df.describe())\n",
        "print(\"\\nMissing Values:\", df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow_text"
      ],
      "metadata": {
        "id": "9O5x59DOka20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16434f29-346e-4ea5-dd89-8e342c42a9cf"
      },
      "id": "9O5x59DOka20",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_text in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (0.16.1)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (4.9.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.60.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.15.0)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub>=0.13.0->tensorflow_text) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44161569",
      "metadata": {
        "id": "44161569"
      },
      "source": [
        "## Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "114ccdd0",
      "metadata": {
        "id": "114ccdd0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4058e87a",
      "metadata": {
        "id": "4058e87a"
      },
      "source": [
        "## Load and Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "69efd42f",
      "metadata": {
        "id": "69efd42f"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Function to convert DataFrame to TensorFlow dataset\n",
        "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
        "    dataframe = dataframe.copy()\n",
        "    labels = dataframe.pop('label')\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dataframe['message'].values, labels.values))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "    ds = ds.batch(batch_size)\n",
        "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "# Convert the split data to TensorFlow datasets\n",
        "batch_size = 32\n",
        "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
        "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18fba6cf",
      "metadata": {
        "id": "18fba6cf"
      },
      "source": [
        "## Bert Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e5f856f3",
      "metadata": {
        "id": "e5f856f3"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "# Selecting BERT model from TensorFlow Hub\n",
        "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'\n",
        "\n",
        "tfhub_handle_encoder = f'https://tfhub.dev/tensorflow/{bert_model_name}/1'\n",
        "tfhub_handle_preprocess = f'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd47f2ae",
      "metadata": {
        "id": "dd47f2ae"
      },
      "source": [
        "## Preprocessing Text for BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c9a28f3c",
      "metadata": {
        "scrolled": false,
        "id": "c9a28f3c"
      },
      "outputs": [],
      "source": [
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83a0ae46",
      "metadata": {
        "id": "83a0ae46"
      },
      "source": [
        "## Build the Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fde8780f",
      "metadata": {
        "id": "fde8780f"
      },
      "outputs": [],
      "source": [
        "def build_classifier_model():\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "    encoder_inputs = preprocessing_layer(text_input)\n",
        "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "    outputs = encoder(encoder_inputs)\n",
        "    net = outputs['pooled_output']\n",
        "    net = tf.keras.layers.Dropout(0.1)(net)\n",
        "    net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
        "    return tf.keras.Model(text_input, net)\n",
        "\n",
        "classifier_model = build_classifier_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b70b008",
      "metadata": {
        "id": "7b70b008"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "13713b2b",
      "metadata": {
        "id": "13713b2b",
        "outputId": "e1c90a83-e62b-49e8-efca-cf37286f3421",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "112/112 [==============================] - 1074s 9s/step - loss: 0.0887 - binary_accuracy: 0.9708 - val_loss: 0.0570 - val_binary_accuracy: 0.9865\n",
            "Epoch 2/5\n",
            "112/112 [==============================] - 1043s 9s/step - loss: 0.0254 - binary_accuracy: 0.9930 - val_loss: 0.0404 - val_binary_accuracy: 0.9865\n",
            "Epoch 3/5\n",
            "112/112 [==============================] - 1035s 9s/step - loss: 0.0128 - binary_accuracy: 0.9966 - val_loss: 0.0392 - val_binary_accuracy: 0.9865\n",
            "Epoch 4/5\n",
            "112/112 [==============================] - 1047s 9s/step - loss: 0.0035 - binary_accuracy: 0.9986 - val_loss: 0.0594 - val_binary_accuracy: 0.9888\n",
            "Epoch 5/5\n",
            "112/112 [==============================] - 1014s 9s/step - loss: 0.0028 - binary_accuracy: 0.9986 - val_loss: 0.0638 - val_binary_accuracy: 0.9877\n"
          ]
        }
      ],
      "source": [
        "# Optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "\n",
        "# Loss function and metrics\n",
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "metrics = tf.metrics.BinaryAccuracy()\n",
        "\n",
        "# Compile the model\n",
        "classifier_model.compile(optimizer=optimizer,\n",
        "                         loss=loss,\n",
        "                         metrics=metrics)\n",
        "\n",
        "# Train the model\n",
        "history = classifier_model.fit(train_ds,\n",
        "                               validation_data=val_ds,\n",
        "                               epochs=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad7a4ffb",
      "metadata": {
        "id": "ad7a4ffb"
      },
      "source": [
        "## Model Evaluation and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "fef56b01",
      "metadata": {
        "id": "fef56b01",
        "outputId": "2ed19604-340b-44fa-a0aa-9fabdc226487",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 84s 2s/step - loss: 0.0440 - binary_accuracy: 0.9919\n",
            "Loss: 0.04401790723204613\n",
            "Accuracy: 0.9919282793998718\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = classifier_model.evaluate(test_ds)\n",
        "print(f'Loss: {loss}')\n",
        "print(f'Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcdd9838",
      "metadata": {
        "id": "fcdd9838"
      },
      "outputs": [],
      "source": [
        "pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6cad9122",
      "metadata": {
        "id": "6cad9122",
        "outputId": "d8f25436-cf78-4ff1-8a7c-b9d0433beecb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 84s 2s/step\n",
            "F1 Score and Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Ham       0.99      1.00      1.00       966\n",
            "        Spam       0.97      0.97      0.97       149\n",
            "\n",
            "    accuracy                           0.99      1115\n",
            "   macro avg       0.98      0.98      0.98      1115\n",
            "weighted avg       0.99      0.99      0.99      1115\n",
            "\n",
            "Area Under the ROC Curve (AUC): 0.997936554254033\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "# Make predictions on the test dataset\n",
        "y_pred = classifier_model.predict(test_ds)\n",
        "y_pred_labels = tf.where(y_pred > 0, 1, 0).numpy()  # Convert logits to binary labels\n",
        "\n",
        "# Extract true labels from test_ds\n",
        "y_true = np.concatenate([y for x, y in test_ds], axis=0)\n",
        "\n",
        "# Calculate F1-Score\n",
        "f1_report = classification_report(y_true, y_pred_labels, target_names=['Ham', 'Spam'])\n",
        "print(\"F1 Score and Classification Report:\")\n",
        "print(f1_report)\n",
        "\n",
        "# Calculate AUC\n",
        "y_pred_probs = tf.sigmoid(y_pred).numpy()  # Convert logits to probabilities\n",
        "auc_score = roc_auc_score(y_true, y_pred_probs)\n",
        "print(\"Area Under the ROC Curve (AUC):\", auc_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e62207b",
      "metadata": {
        "id": "8e62207b"
      },
      "source": [
        "## Model Saving and Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "757a42b6",
      "metadata": {
        "id": "757a42b6"
      },
      "outputs": [],
      "source": [
        "saved_model_path = './spam_classifier_bert'\n",
        "classifier_model.save(saved_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4177d9b8",
      "metadata": {
        "id": "4177d9b8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(\"Current TensorFlow version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "5e19d37b",
      "metadata": {
        "id": "5e19d37b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}